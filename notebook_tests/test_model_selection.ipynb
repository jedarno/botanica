{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be176fa-555e-4a6e-b9fe-152f3624e84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zfac230/botanica_project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zfac230/.venv/botanica/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8c36f6a-e0af-4d2c-a3a2-073af50d38a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zfac230/.venv/botanica/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acacc3e0-c52a-410c-a64b-2e16a1daa4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e62293bf-0bdb-4fd5-b304-6b59f2e6b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b1b309-5790-4234-b791-f5c4d9e34496",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = trainset.classes\n",
    "num_class = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "385fad6f-9075-44c7-bbb3-a0eda75ba039",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ed5348-6c63-4297-bbea-11d3f2ff0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = TinyModel()\n",
    "model2 = TinyModel()\n",
    "model3 = TinyModel()\n",
    "models = [model1, model2, model3]\n",
    "weights = [0.1, 0.5, 0.8]\n",
    "threshold=0.5\n",
    "epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9accecc4-83f1-4af9-8575-9a95b88e2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "pso_pop = 7\n",
    "fa_pop = 3\n",
    "dim = 3\n",
    "w = 0.5\n",
    "alpha_0 = 0.9\n",
    "alpha_f = 0.1\n",
    "df = 0.5\n",
    "states = np.array([[1.3,0.8],\n",
    "                   [1.2,1.2],\n",
    "                   [0.6,1.5]])\n",
    "maxiter = 10\n",
    "fa_options = {'bmin':1, 'gamma':0.8, 'alpha':0.2}\n",
    "search_bounds = (np.array([0] * dim), np.array([1] * dim))\n",
    "k_vals = 0.8, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b227ab3-af10-4739-bd92-c334be230477",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = TinyModel().to(mps_device)\n",
    "model2 = TinyModel().to(mps_device)\n",
    "model3 = TinyModel().to(mps_device)\n",
    "models = [model1, model2, model3]\n",
    "weights = [0.1, 0.5, 0.8]\n",
    "threshold=0.5\n",
    "epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee0556c5-9356-45e7-9714-248a299fdc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:02<00:00, 425.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from botanica.transformer.model_selection import _get_model_output\n",
    "output = _get_model_output(model1, trainloader, mps_device)\n",
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94f42c65-2020-42fe-8d48-972c8de49148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 307.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 450.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 460.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from botanica.transformer.model_selection import get_suite_outputs\n",
    "suite_train_output = get_suite_outputs(models, testloader, mps_device)\n",
    "len(suite_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb6b1120-ddb7-43d0-9f58-8f8d2fdeb963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 485.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 420.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 398.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suite_val_output = get_suite_outputs(models, testloader, mps_device)\n",
    "len(suite_val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0101a163-d891-4433-b2ce-c9ac0e60a76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "from botanica.transformer.model_selection import get_ensemble_output\n",
    "ens_train_out = get_ensemble_output(suite_train_output, weights)\n",
    "ens_val_out = get_ensemble_output(suite_val_output, weights)\n",
    "print(len(ens_train_out))\n",
    "print(len(ens_val_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e302ba-94c1-4175-a4f2-929d3c7ce490",
   "metadata": {},
   "outputs": [],
   "source": [
    "sftmx = torch.nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08c49662-6b78-4f05-a9a4-db07ee76929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3837, 0.2327, 0.3837]])\n",
      "tensor([[0.3333, 0.3333, 0.3333]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.4340, 1.1321, 1.4340]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = torch.Tensor([[1,.5,1]])\n",
    "out2 = torch.Tensor([[1,1,1]])\n",
    "print(sftmx(out1))\n",
    "print(sftmx(out2))\n",
    "weights = [1, 2]\n",
    "test_out = get_ensemble_output([out1, out2], weights)\n",
    "test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f9487ae-ce64-4868-92b6-45ce1a71494e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61d5b77c-2131-4c48-a5b0-c6543007414e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from botanica.transformer.model_selection import get_model_suite\n",
    "get_model_suite([0.3, 0.5, 0.8], models, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb5a56f3-460d-42dc-9328-d1b6456833f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3026\n",
      "top_k acc: 0.1010, 0.3000, 0.5003\n"
     ]
    }
   ],
   "source": [
    "from botanica.transformer.model_selection import fitness_wrapper_ensemble\n",
    "num_models = len(suite_val_output)\n",
    "fitness = fitness_wrapper_ensemble(ens_val_out, num_models, (0.8,0.2), mps_device, classes, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f96bd74a-d251-4ceb-892d-c4c27e5277a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1475, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ad083e-19f2-4cad-baf0-fa25b2954365",
   "metadata": {},
   "source": [
    "Testing tensor loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "528e9255-1a32-471c-b6f4-508bab85a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(out1, \"model_1_val_logits.pt\")\n",
    "torch.save(out2, \"model_2_val_logits.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "118bb0b0-c39b-4554-86c1-08adede7a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botanica.transformer.model_selection import load_output_from_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab2f47e5-d34d-4e14-9c71-5e6fe9457516",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensors = load_output_from_dir('.', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2697030f-8653-429f-aaef-e479938d102e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.5000, 1.0000]],\n",
       "\n",
       "        [[1.0000, 1.0000, 1.0000]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf7e0be3-8a64-4caa-894a-cbf1afb0ceda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.5000, 1.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5f0d85a-62d8-45e5-8bc7-9988c7113638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.5000, 1.0000]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d109981b-d68b-492a-b741-d4e938f01295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdce85be-3096-41e4-9e3a-059f4f14a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.stack(suite_val_output)\n",
    "outputs = torch.rand(outputs.shape).to(mps_device)\n",
    "weights = np.array([1, 1.1, 0.1])\n",
    "def swarm_wrapper(position):\n",
    "    val_suite_index = get_model_suite(position, outputs, threshold)\n",
    "    val_suite = outputs[val_suite_index]\n",
    "    suite_weights = weights[val_suite_index]\n",
    "    num_models = len(val_suite)\n",
    "    val_out = get_ensemble_output(val_suite, weights)\n",
    "    fitness = fitness_wrapper_ensemble(val_out, num_models, (0.8,0.2), mps_device, classes, testset)\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1aa16c86-b35b-4628-83f0-ae7eac929d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10000, 10])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "450b0157-8d3e-4658-8f2e-69bbcf569a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3037\n",
      "top_k acc: 0.0995, 0.3038, 0.5016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.2796, device='mps:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swarm_wrapper([1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9aa6974-9d42-4244-bce4-93a1e838b02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3041\n",
      "top_k acc: 0.0977, 0.2994, 0.5018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.2782, device='mps:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swarm_wrapper([0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdb7e3d9-1443-4192-8026-7d2b294c8f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3049\n",
      "top_k acc: 0.0942, 0.2943, 0.4893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.2754, device='mps:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swarm_wrapper([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6736f81f-60c7-4438-8f1e-757b3100855e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9602, 0.9199, 0.4060,  ..., 0.8564, 0.9751, 0.5566],\n",
       "        [0.6508, 0.2272, 0.9987,  ..., 0.6583, 0.0249, 0.6021],\n",
       "        [0.6796, 0.0462, 0.4574,  ..., 0.6426, 0.1015, 0.8857],\n",
       "        ...,\n",
       "        [0.2283, 0.6087, 0.3744,  ..., 0.9334, 0.5637, 0.2899],\n",
       "        [0.7841, 0.2136, 0.9075,  ..., 0.7599, 0.7701, 0.6572],\n",
       "        [0.5244, 0.1176, 0.2690,  ..., 0.7935, 0.6329, 0.2126]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6971976-9306-4af7-94a8-1c56198bb075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fa1bd32-45cf-414b-b3fa-7a933ac44b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10000, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(suite_val_output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d518d9f6-86fc-4a11-9de1-f80cd092565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "475970c0-b062-4d5e-8ce7-862ac928c850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testset.targets) == torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1b2c4ac-1b01-4980-a21d-ba194b9a1f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testset.targets) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f68791cc-c9f8-4909-9641-42ff42577ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73187da0-b741-42c5-bb1c-d41913013fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testset.targets) == Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95d03ede-85f1-4906-a7bf-6279c10dacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.targets = testset.targets.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7721b10f-cbce-49d9-b8f0-1a1329d00941",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbotanica\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marchitecture\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transformer_ensemble_weighted\n\u001b[0;32m----> 2\u001b[0m ensemble_model \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_ensemble_weighted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/botanica_project/botanica/transformer/architecture.py:79\u001b[0m, in \u001b[0;36mtransformer_ensemble_weighted.__init__\u001b[0;34m(self, models, weights)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels \u001b[38;5;241m=\u001b[39m models\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msftmx \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m weights\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from botanica.transformer.architecture import transformer_ensemble_weighted\n",
    "ensemble_model = transformer_ensemble_weighted(models, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4c3e9-6807-4768-bb90-fb75462da27d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botanica",
   "language": "python",
   "name": "botanica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
